services:
  postgres:
    image: postgres:16
    container_name: books_postgres
    restart: always
    environment:
      POSTGRES_DB: booksdb
      POSTGRES_USER: ${PG_USER}
      POSTGRES_PASSWORD: ${PG_PASS}
    ports:
      - "5432:5432"
    volumes:
      - ./pgdata:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${PG_USER} -d booksdb"]
      interval: 5s
      timeout: 5s
      retries: 5

  qdrant:
    image: qdrant/qdrant:v1.15.1
    container_name: qdrant
    ports:
      - "6333:6333"
    environment:
      QDRANT__STORAGE__PATH: /qdrant/storage
      # Keep WAL preallocation small so it fits even on limited disks
      QDRANT__STORAGE__WAL__CAPACITY_MB: 16
    volumes:
      # Bind to a project-local path so storage lands on the main disk, not a tiny temp mount
      - ./qdrant_data:/qdrant/storage

  phoenix:
    image: arizephoenix/phoenix:latest
    container_name: phoenix
    ports:
      - "6006:6006"
      - "4317:4317"
    environment:
      PHOENIX_WORKING_DIR: /phoenix-data
    volumes:
      - phoenix_data:/phoenix-data

  ollama:
    image: ollama/ollama:latest
    container_name: doc-mate-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-models:/root/.ollama
    restart: unless-stopped

    # Resource limits to prevent system crashes
    deploy:
      resources:
        limits:
          # Limit memory to prevent OOM crashes
          # 10GB for llama3.1:8b (8GB model + 2GB overhead)
          memory: 10G
          cpus: '4.0'  # Limit CPU usage
        reservations:
          memory: 8G  # Minimum memory reservation

    environment:
      # Limit concurrent requests to prevent overload
      OLLAMA_NUM_PARALLEL: 1
      OLLAMA_MAX_LOADED_MODELS: 1

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  app:
    build: .
    container_name: bookmate_app
    restart: always
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      PG_USER: ${PG_USER}
      PG_PASS: ${PG_PASS}
      PG_HOST: postgres
      PG_PORT: 5432
      PG_DB: booksdb
      QDRANT_HOST: qdrant
      QDRANT_PORT: 6333
      PHOENIX_COLLECTOR_ENDPOINT: http://phoenix:4317
      LLM_PROVIDER: ${LLM_PROVIDER:-openai}
      OLLAMA_BASE_URL: http://ollama:11434/v1
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.2:3b}
      PRIVACY_MODE: ${PRIVACY_MODE:-false}
    ports:
      - "7860:7860"
    volumes:
      - ./DATA:/app/DATA
      - ./INDEXES:/app/INDEXES
      - ./src:/app/src
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_started
      phoenix:
        condition: service_started

volumes:
  phoenix_data: {}
  pgdata:
    driver: local
  ollama-models:
    name: doc-mate-ollama-models
